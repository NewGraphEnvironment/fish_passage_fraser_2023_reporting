---
title: "0110-photos-resize"
date: "Created: 2024-10-21 | Updated: `r format(Sys.Date(), '%Y-%m-%d')`"
output: 
  html_document:
    code_folding: "hide"
params:
  repo_owner: "NewGraphEnvironment"
  repo_name: "fish_passage_fraser_2023_reporting"
  gis_name: "sern_fraser_2024"
  job_name: "2024-074-sern-fraser-fish-passage"
---


```{r setup, echo=TRUE, include = TRUE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = "100%", eval = FALSE)
options(scipen=999)
options(knitr.kable.NA = '--') #'--'
options(knitr.kable.NAN = '--')
```



```{r params}
# grab the files from mergin and move to project using linux cmd
# mv -v ~/Projects/gis/mergin/bcfishpass_elkr_20220904/photos/* ~/Projects/current/2022-056-nupqu-elk-cwf/data/photos/mergin/originals
# mv -v ~/Projects/gis/mergin/bcfishpass_skeena_20220823-v225/photos/* ~/Projects/current/2022-049-sern-skeena-fish-passage/data/photos/mergin/

# Build Local Directory  ------------------------------------------------------------
dir_photos_mergin_raw <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, "/ignore_mobile/photos/"))
dir_photos_mergin_resized <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, "/ignore_mobile/photos_resized"))
# dir_photos_processed_final <- fs::path_expand(fs::path("~/Projects/data/", params$gis_name, "/photos/"))
dir_photos_originals <- fs::path_expand(fs::path("~/Library/CloudStorage/OneDrive-Personal/Projects", params$job_name, "/data/photos/"))
dir_photos_onedrive <- fs::path_expand(fs::path("~/Library/CloudStorage/OneDrive-Personal/Projects", params$job_name, "data/photos/"))
```

# Resize

```{r dir-create}
# we are going to resize the original photos and move them to onedrive just in case we need to do homework
fs::dir_create(fs::path(dir_photos_onedrive, "ai"), recurse = TRUE)
fs::dir_create(fs::path(dir_photos_onedrive, "ls"), recurse = TRUE)
```

```{r dir-shared-resize}
fpr::fpr_photo_resize_batch(
  dir_source = fs::path(dir_photos_originals,"ai/originals"),
  dir_target = fs::path(dir_photos_onedrive, "ai")
)

fpr::fpr_photo_resize_batch(
  dir_source = fs::path(dir_photos_originals,"ls/originals"),
  dir_target = fs::path(dir_photos_onedrive, "ls")
)

# move the originals off of onedrive to the local computer to manage storage space

dir_to <- fs::path("/Users/airvine/Projects/current", params$job_name, "data/photos/ai")
dir_from<- fs::path(dir_photos_originals,"ai/originals")
fs::dir_create(dir_to, recurse = TRUE)
fs::dir_copy(dir_from,
             dir_to)
fs::dir_delete(dir_from)

dir_to <- fs::path("/Users/airvine/Projects/current", params$job_name, "data/photos/ls")
dir_from <- fs::path(dir_photos_originals,"ls/originals")
fs::dir_create(dir_to, recurse = TRUE)
fs::dir_copy(dir_from,
             dir_to)
fs::dir_delete(dir_from)

```


```{r gis-resize}
# QGIS mergin photos-----------------------------------------------------------------------------------------------------
## Clean up the mergin file----------------------------------------------------------------------------------------------------
# remove photos.txt file included in project when created (was to allow mergin git to see the photos dir) but needs
# to be removed or ignored to not break fpr_photo_resize_batch


###!!! make sure you are synced with the server here 
fs::file_delete(
  fs::path(dir_photos_mergin_raw, "/photos.txt")
)

## Resize----------------------------------------------------------------------------------------------------
# resize the photos and change the extension to JPG for consistency and to avoid issues with fpr_photo calls in reporting
# sync to mergin after copying to new dir (resized) and removing originals
# record version number of mergin project in issue for now to track

# get a list of the photos
p <- fs::dir_ls(dir_photos_mergin_raw, recurse = T)


# see how large the photos are in MB rounded to 1 decimal using purrr
s <- p |> 
  purrr::map(file.info) |> 
  purrr::map_dbl("size")/1024/1024

# identify the range of sizes
range(s)
# [1] 0.1013966 0.5582142 Not bad.  Lets resize anyway so that we know they fit the reporting

# create the target directory
fs::dir_create(dir_photos_mergin_resized, recurse = TRUE)

fpr::fpr_photo_resize_batch(
  dir_source = dir_photos_mergin_raw,
  dir_target = fs::path(dir_photos_mergin_resized)
)


# quick check to see if the photos are all accounted for
identical(
  length(
    fs::dir_ls(dir_photos_mergin_raw, recurse = T)),
  length(
    fs::dir_ls(dir_photos_mergin_resized, recurse = T))
)

# erase all the photos in the original directory
fs::dir_delete(dir_photos_mergin_raw)

# recreate the photos.txt file so the form still works
fs::dir_create(dir_photos_mergin_raw)
fs::file_create(
  fs::path(dir_photos_mergin_raw, "photos.txt")
)

# push to mergin - record version number of mergin project in issue to track

##!!!!!!!!!!!!!!!!!!!! special case start
#not sure why this extra dir is here but will put photos with  rest
fpr::fpr_photo_resize_batch(
  dir_source = "/Users/airvine/Projects/gis/sern_peace_fwcp_2023/photos",
  dir_target = fs::path(dir_photos_mergin_resized)
)

fs::dir_delete("/Users/airvine/Projects/gis/sern_peace_fwcp_2023/photos")
# push to mergin - record version number of mergin project in issue to track
##!!!!!!!!!!!!!!!!!!!! special case end
```

```{r dir-site-create-pscis}
form_raw <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'form_pscis.gpkg'))
form_new <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'data_field/2024/form_pscis_2024_raw.gpkg'))

#this can be run for the ow photos once the issue with ids is resolved
# form_new <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'data_field/2024/form_pscis_ow_2024.gpkg'))


fs::dir_create(fs::path_dir(form_new))

# copy the form to the new field directory
fs::file_copy(
  form_raw,
  form_new
)

form_pscis_photos_raw <- fpr::fpr_sp_gpkg_backup(
  form_new,
  update_site_id = TRUE, #this checks for duplicate photos 
  # turned this off for now but was on first time
  write_back_to_path = FALSE,
  return_object = TRUE
) |> 
  dplyr::arrange(site_id)

# check for empty sites
form_pscis_photos_raw |>
  dplyr::filter(is.na(site_id)) |>
  nrow()

# NOT RUN for fraser 2024 - just putting sorted photos on OneDrive so simplicity. 
# create site photo directories right on mergin to make them easy to share...
form_pscis_photos_raw |>
  dplyr::pull(site_id) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = dir_photos_mergin_raw
  )

# also create on onedrive
form_pscis_photos_raw |>
  dplyr::pull(site_id) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = paste0(dir_photos_onedrive, "/")
  )
```

```{r rename-qa-pscis}

### HACK for Fraser 2024 - which does not contain the column `photo_extra3_tag` so fpr_photo_rename() is failing ###
# See issue here https://github.com/NewGraphEnvironment/fpr/issues/39#issuecomment-2443203763

# we will just add in the `photo_extra3_tag` column and make it NA.

form_pscis_photos_raw_hack <- form_pscis_photos_raw |> 
  dplyr::mutate(photo_extra3_tag = NA)

form_pscis_photos_raw <- form_pscis_photos_raw_hack

rm(form_pscis_photos_raw_hack)

### END HACK ###


# NOTE - needed to add a / to the end of the dir names for now until we update `fpr::fpr_photo_rename` with fs functions
fpr::fpr_photo_rename(
  dat = form_pscis_photos_raw,
  dir_from_stub = paste0(dir_photos_mergin_resized, "/"),
  dir_to_stub = paste0(dir_photos_onedrive, "/")
)
##this section does not seem to be working
qa_missing <- fpr::fpr_photo_qa_missing_all(
  dat = form_pscis_photos_raw,
  # needed to add a / to the end of the dir names for now
  dir_photos =  paste0(dir_photos_onedrive, "/")
) 

qa_all <- fpr::fpr_photo_qa(
  dat = form_pscis_photos_raw,
  # needed to add a / to the end of the dir names for now
  dir_photos = paste0(dir_photos_onedrive, "/")
) |>
  data.table::rbindlist(fill = TRUE)

qa <- fpr::fpr_photo_qa_df(
  dat = form_pscis_photos_raw,
  # needed to add a / to the end of the dir names for now
  dir_photos = paste0(dir_photos_onedrive, "/")
)

# here is the test for missing individual photos
test <- fpr::fpr_photo_qa(dat = form_pscis_photos_raw) |>
  bind_rows() |>
  dplyr::filter(if_any(everything(), is.na))
```


# FISS Site - Rename the photos from the FISS cards and remove duplicates

CANT USUALLY DO THIS UNTILL WE SUBMIT THE DATA AND GET THE PSCIS IDS

```{r dir-site-create-fiss}

# copy the gpkg to the new location - this is just as easily done by hand. Named it weird
form_raw <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'form_fiss_site.gpkg'))
form_new <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'data_field/2024/form_fiss_site_2024.gpkg'))

fs::dir_create(fs::path_dir(form_new))

# copy the form to the new field directory
fs::file_copy(
  form_raw,
  form_new
)

form_fiss_photos_raw <- fpr::fpr_sp_gpkg_backup(
  form_new,
  write_back_to_path = FALSE,
  return_object = TRUE,
  col_easting = "utm_easting",
  col_northing = "utm_northing"
) 


form_fiss_photos <- form_fiss_photos_raw |> 
  tidyr::separate(local_name, into = c('site', 'photo_tag_site'),
                  extra = "merge", 
                  fill = "right", 
                  remove = FALSE) |> 
  tidyr::separate(local_name, into = c('site', 'location', 'ef'), remove = FALSE) |> 
  mutate(site_id = paste0(site, location))

# check for duplicate sites
form_fiss_photos |>
  dplyr::filter(!is.na(local_name)) |>
  group_by(local_name) |>
  dplyr::filter(n()>1) |>
  nrow()

# check for empty sites
form_fiss_photos |>
  dplyr::filter(is.na(local_name)) |>
  nrow()

# create site photo directories right on mergin to make them easy to share...
form_fiss_photos |>
  dplyr::pull(site) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = dir_photos_mergin_raw
  )

# also create the directories on onedrive
form_fiss_photos |>
  dplyr::pull(site) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = paste0(dir_photos_onedrive, "/")
  )
```


We don't qa with the fpr functions bc they just check for pscis photos
```{r rename-fiss}

# NOTE - needed to add a / to the end of the dir names for now untill we update fpr::fpr_photo_rename with fs functions
fpr::fpr_photo_rename(
  dat = form_fiss_photos,
  # we need to pick the correct column for this dataframe
  col_directories = site,
  dir_from_stub = paste0(dir_photos_mergin_resized, "/"),
  dir_to_stub = paste0(dir_photos_mergin_raw, "/"),
  col_string_add = TRUE,
  # we just made this column
  col_string_append = photo_tag_site
)

```


```{r}
# quick check to see if the photos are all accounted for
identical(
  # 189
  length(
    fs::dir_ls(dir_photos_mergin_raw, recurse = T)),
  # 202 - there were a few photos in the "Photos" directory from a mistake in one of the forms... Can't rememver 
  length(
    fs::dir_ls(dir_photos_mergin_resized, recurse = T))
)
```

# Monitoring Form


```{r dir-site-create-pscis}
form_raw <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'form_monitoring.gpkg'))
form_new <- fs::path_expand(fs::path("~/Projects/gis/", params$gis_name, 'data_field/2024/form_monitoring_2024.gpkg'))

fs::dir_create(fs::path_dir(form_new))

# copy the form to the new field directory
fs::file_copy(
  form_raw,
  form_new,
  overwrite = T
)

form_photos_raw <- fpr::fpr_sp_gpkg_backup(
  form_new,
  update_site_id = TRUE,
  # turned this off for now but was on first time
  write_back_to_path = FALSE,
  return_object = TRUE,
  col_easting = "utm_easting",
  col_northing = "utm_northing"
) 

# check for duplicate sites
form_photos_raw |>
  dplyr::filter(!is.na(site_id)) |>
  group_by(site_id) |>
  dplyr::filter(n()>1) |>
  nrow()

# check for empty sites
form_photos_raw |>
  dplyr::filter(is.na(site_id)) |>
  nrow()

# create site photo directories right on mergin to make them easy to share...
form_photos_raw |>
  dplyr::pull(site_id) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = dir_photos_mergin_raw
  )

# also create on onedrive
form_photos_raw |>
  dplyr::pull(site_id) |>
  as.character() |>
  purrr::map(
    fpr::fpr_photo_folders, path = paste0(dir_photos_onedrive, "/")
  )
```

```{r rename-monitoring}

# NOTE - needed to add a / to the end of the dir names for now untill we update fpr::fpr_photo_rename with fs functions
fpr::fpr_photo_rename(
  dat = form_photos_raw,
  dir_from_stub = "/Users/airvine/Projects/gis/sern_peace_fwcp_2023b/photos/",
  dir_to_stub = "/Users/airvine/Projects/gis/sern_peace_fwcp_2023b/photos/"
)

```


# Remove duplicates

After we sort the photos that came off the camera by hand into their directories we can amalgamate with the renamed photos.

When a photo is renamed using `fpr::fpr_photo_rename` the photo renamed is not duplicated. However, we take many more photos on our phones than we upload to `Mergin` via our field forms. We subsequently transfer all of our field photos off of our phones onto company drives. Because we use the gallery to upload our photos to `Mergin` (an important procedure so we don't lose photos when `mergin` glitches) we have a lot of duplicates. We use the `fpr::fpr_photo_remove_dupes` function to remove duplicates. We also have a `min_replicates` argument that allows us to remove photos that are not duplicated at least `n` times.

```{r photos-no-metadata}

##### HACK for missing metadata issue, explained here https://github.com/NewGraphEnvironment/fish_passage_skeena_2024_reporting/issues/4#####

# looks we are having the same issue as documented above, where there are some photos with no metadata so they are being scene as duplicates. We will follow the same fix as in that issue:

# These are the photos that are missing metadata and are NOT duplicated but they are being seen as duplicates. 
photos_no_metadata <- photos_dry_run |> 
  dplyr::filter(is.na(date_time_original))

# create new folders
path_photos_no_metadata <- fs::path(dir_photos_onedrive, "photos_no_metadata")
fs::dir_create(path_photos_no_metadata)

#make the site specific folders
sites_no_metadata <- photos_no_metadata |> 
  dplyr::mutate(site_number = basename(dirname(source_file))) |> 
  dplyr::distinct(site_number) |> 
  dplyr::pull(site_number) |> 
  purrr::map(
    fpr::fpr_photo_folders, path = paste0(path_photos_no_metadata, "/"))


#these are the photos we are copying
files_to_copy <- photos_no_metadata |> 
  dplyr::pull(source_file)

# make the paths for where we are copying the photos to
photos_to_paste <- stringr::str_remove(files_to_copy, "^.*sorted/")
files_to_paste <- fs::path(path_photos_no_metadata, photos_to_paste)


# Copy files from folder `photos/sorted` to `photos/photos_no_metadata`
purrr::map2(files_to_copy, files_to_paste, ~ fs::file_copy(.x, .y, overwrite = TRUE))

# Check to see they moved successfully
# Now remove them from the `photos/sorted` folders
fs::file_delete(files_to_copy)



# run remove dupes as usual

# use fpr_photo_remove_dupes to see the duplicated photos
photos_dry_run <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))

# use fpr_photo_remove_dupes to see the triplicated photos
photos_dry_run3 <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"), min_replicates = 3)

# # # actually run the removal of the first un-renamed photo
# fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"),
#                             dry_run = F)

# now there should only be photos that had triplets. The un-renamed photos have been removed so there will only be duplicates of renamed photos. These should be same photos as in photos_dry_run3.
photos_dry_run_after <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))

# now run the removal of the duplicated renamed photos (photos that had triplets)
# fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"),
#                             dry_run = F)

# Now there should be no duplicated of any kind, this object should be empty. 
photos_dry_run_after <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))
                                                  

# backup the dry runs to a csv so we can track which photos were removed.
readr::write_csv(photos_dry_run, "data/inputs_extracted/photo_duplicate_rm_log.csv" )


# DONT FORGET !!!
# Move files back from folder `photos/photos_no_metadata` to `photos/sorted`
purrr::map2(files_to_paste, files_to_copy, ~ fs::file_copy(.x, .y))

```



```{r remove-dupes}

# temporarily move the site-specific folders on onedrive to a "sorted" folder so only the site-specific folders are present (and not the other folders in the photo folder)

# use fpr_photo_remove_dupes to see the duplicated photos
photos_dry_run <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))

# use fpr_photo_remove_dupes to see the triplicated photos
photos_dry_run3 <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"), min_replicates = 3)


# # actually run the removal of the first un-renamed photo
# fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"),
#                             dry_run = F)

# now there should only be photos that had triplets. The un-renamed photos have been removed so there will only be duplicates of renamed photos. These should be same photos as in photos_dry_run3.
photos_dry_run_after <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))

# # now run the removal of the duplicated renamed photos (photos that had triplets)
# fpr::fpr_photo_remove_dupes('fs::path(dir_photos_onedrive, "sorted"),
#                             dry_run = F, remove_renamed = TRUE)

# Now there should be no duplicated of any kind, this object should be empty. 
photos_dry_run_after <- fpr::fpr_photo_remove_dupes(fs::path(dir_photos_onedrive, "sorted"))
                                                  

# backup the dry runs to a csv so we can track which photos were removed.
readr::write_csv(photos_dry_run, "data/backup/photo_duplicate_rm_log.csv" )

```
